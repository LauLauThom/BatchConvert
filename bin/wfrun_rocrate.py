"""
Module to create a WF (run) crate for a run of the BatchConvert tool i.e a conversion.
"""
import os
from pathlib import Path
import shutil, json
import time
import warnings
import rocrate
#print(rocrate.__path__)

from rocrate.rocrate import ROCrate
from rocrate.model   import ComputerLanguage
from rocrate.model.entity import Entity
from rocrate.model.person import Person
from rocrate.model.contextentity import ContextEntity
from typing import Any, Dict, List, Literal, Optional, cast

get_identifier = lambda id : id if id.startswith("#") else f"#{id}"
"""Get a ROCrate compliant identifier for a given string, i.e should start with #"""

def load_params_json(path:str|Path) -> Dict[str, Any]:
    """Load the param json, casting the bool which were not properly encoded."""

    with open(path) as file:
        content_dict : dict[str, Any] = json.load(file)
    
    for key, value in content_dict.items():

        if value in ("True", "False"): 
            content_dict[key] = eval(value) # replace with an actual boolean
        
    return content_dict


class BatchConvert_RunCrateMaker(object):
    """
    Custom class for the BatchConvertWorkflowRunCrate, adding convenience functions.  
    Dont directly extend a ROCrate, we dont want to give the option to save the crate anywhere, since we also need to move files around.  
    """

    # mapping python type to the rocrate equivalent
    PY_TYPE_TO_RO_TYPE = {
        int:"Integer", 
        str:"Text",
        bool:"Boolean",
    }

    # Dict with optional description for the parameters of BatchConvert that are added to the crate.
    # Used in add_FormalParameter. 
    PARAMETERS_TO_DESCRIPTION = {
        "prov" : "If a WorkflowRun RO Crate should be created for the run, i.e the output directory is turned into a ROCrate.",
    }
    
    def __init__(self, 
                 batch_convert_root_directory : str, 
                 param_dir:Optional[str|Path] = None, 
                 name = "", 
                 description = "", 
                 license = ""):
        """
        Create a workflow run crate after conversion of an image dataset with BatchConvert.  
        This constructor only populates the default infos that do not change, but does not parse the json files with the actual parameter values.   
        
        batch_convert_root_directory
        ----------------------------
        Where the BatchConvert script files are.

        param_dir
        --------
        Directory of the params.json file.  
        If not provided, default to home/.batchconvert/params  

        name
        ----
        Optional name of the crate, a default name is created if not provided.  
        Use for the attribute "name" of the root dataset of the crate.  

        description
        -----------
        Optional description for the crate.
        By default will be "Conversion of dataset {name} to format {format}" where name is the name of the source directory passed to BatchConvert, and format is the conversion format (ometiff or omezarr).
        """
        
        super().__init__()
        self.crate = ROCrate()

        param_dir = Path(param_dir) if param_dir else Path.home().joinpath(".batchconvert") \
                                                                 .joinpath("params")
        
        if not param_dir.exists():
            raise FileNotFoundError(param_dir)

        ## Add parameter json files to the crate
        # json_param : parameters used for the run
        path_json_param = param_dir / "params.json"

        # json with default paraemeters, used to compare with the params.json file
        path_json_default_param = param_dir / "params.json.default"

        if not path_json_param.exists():
            raise FileNotFoundError(path_json_param)
        
        if not path_json_default_param.exists():
            raise FileNotFoundError(path_json_default_param)
        
        # Not listing this params.json as an input of the main CreateAction
        # it is not directly passed to the BatchConvert command line
        # it should rather be an input of one of the subworkflows (actual nexflow pipeline) 
        self.crate.add_file(path_json_param, 
                            dest_path="params/params.json",
                            properties = {"name":"parameters",
                                          "description": "Parameters used by the nextflow workflow, called by BatchConvert. This json is generated by the BatchConvert util.",
                                          "encodingFormat":"text/json"    
                            }) 
        
        self.crate.add_file(path_json_default_param, 
                            dest_path="params/params.json.default",
                            properties = {"name":"default_parameters",
                                          "description": "Default values for parameters not explicitely passed to BatchConvert.",
                                          "encodingFormat":"text/json"    
                            })
        
        self._json_param = load_params_json(path_json_param)
        """Parameters used for the run, as a dict."""

        self._json_default_param = load_params_json(path_json_default_param)
        """Default parameters, as a dict."""

        self._add_workflows(batch_convert_root_directory)

        # Add the authors and institution potentially
        # works but not added as author of the workflow
        # TODO add more authors
        author = self.crate.add(Person(self.crate, 
                                       identifier="https://orcid.org/0000-0001-9823-0581", 
                                       properties={"name" : "Bugra Ã–zdemir"})) # the O with umlaut gets a unicode character code, which is OK in a UI it renders properly
        self.crate.root_dataset["author"] = [author]
        #crate["Authors"] = author # nope

        # Create or get the creative work nodes, for the conformsTo at the dataset level (not the ones of the ro-crate-metdata.json entity)
        wf_crate_profile = self.crate.get("https://w3id.org/workflowhub/workflow-ro-crate/1.0")

        if wf_crate_profile is None :
             wf_crate_profile = self.crate.add_jsonld({"@id": "https://w3id.org/workflowhub/workflow-ro-crate/1.0",
                                                        "@type": "CreativeWork",
                                                        "name": "Workflow RO-Crate",
                                                        "version": "1.0"
                                                        })

        process_profile = self.crate.add_jsonld({ "@id": "https://w3id.org/ro/wfrun/process/0.1",
                                                "@type": "CreativeWork",
                                                "name": "Process Run Crate",
                                                "version": "0.1"})

        wfrun_profile = self.crate.add_jsonld({"@id": "https://w3id.org/ro/wfrun/workflow/0.1",
                                               "@type": "CreativeWork",
                                               "name": "Workflow Run Crate",
                                               "version": "0.1"
                                                })
        
        self.crate.root_dataset["conformsTo"] = [process_profile, wfrun_profile, wf_crate_profile]

        # Add default name and description to the root element of the crate
        self.crate.name = name
        self.crate.description = description
        self.crate.license = license

        #  Add the main CreateAction to the crate, that uses the main workflow as the instrument
        self.main_action : Entity = cast(Entity, self.crate.add_action(identifier="batchconvert_main_run",
                                                                       instrument = self.main_wf,
                                                                       properties={"name" : "Run of BatchConvert"})) # TODO could parse the start/end time from the netflox.log file
        """
        Reference to the main CreateAction, with the main workflow as instrument.  
        The reference can be used to add data entities to the object/results attributes (i.e documenting values taken by the parameters during the run).
        """
        
        # Process the content of the json, adding FormalParameter and PropertyValue entities to the main workflow and main action.
        self._process_param_json()


    def _add_workflows(self, batch_convert_root_directory:str):
        """
        Add main workflow entity (BatchConvert) and subworkflows (nextflow) called by the main workflow.  
        The subworkflows are added as part of the main workflow, so they can be referenced in the CreateAction.
        """

        # crate.add_workflow("batchconvert", main=True, lang = "shell") # throws an error, currently lang has to be one of "cwl", "galaxy", "knime", "nextflow", "snakemake", "compss", "autosubmit"
        # However one can also pass a ComputerLanguage object to lang, see https://github.com/ResearchObject/ro-crate-py/issues/218#issuecomment-2753694857
        bash_url = "https://www.gnu.org/software/bash/"
        bash = ComputerLanguage(self.crate, identifier="#bash", properties = {"name" : "Bash",
                                                                              "identifier": {"@id": bash_url},
                                                                              "url": {"@id": bash_url}
                                                                             })
        # need to add the item first then reference it
        self.crate.add(bash) 

        # the wf file will be copied from the source, to the directory where the crate will be saved (using crate.write)
        self.main_wf = cast(Entity, self.crate.add_workflow(source = os.path.join(batch_convert_root_directory, "batchconvert"), 
                                                            main=True, 
                                                            lang = bash))  # type: ignore

        # Adding the subworkflows has part of the WF crate
        # For a run, one could omit the one not used, or only mention the one used via a createAction
        # Same process, create the entities and add them to the crate (done in one go by add_workflow here), then link them to the main wf
        workflow_tiff = self.crate.add_workflow(source = os.path.join(batch_convert_root_directory, "pff2omezarr.nf"),
                                                main = False,
                                                lang = "nextflow")

        workflow_zarr = self.crate.add_workflow(source = os.path.join(batch_convert_root_directory, "pff2ometiff.nf"), 
                                                main = False,
                                                lang = "nextflow")

        # Add description to the secondary workflow
        desc_template = "Nextflow workflow executed when passing the argument (i.e converting to) '{}' as first argument to the BatchConvert utility."
        workflow_tiff["description"] = desc_template.format("ometiff") # type: ignore
        workflow_zarr["description"] = desc_template.format("omezarr") # type: ignore

        self.main_wf["hasPart"] = [workflow_tiff, workflow_zarr]  # type: ignore
        self.main_wf["url"]     = ["https://github.com/Euro-BioImaging/BatchConvert"]


    def _process_param_json(self):
        """
        Parse the params.json file to extract the parameters used for the run.  
        This function adds `FormalParameter` entities as `input` to the main workflow, 
        and `PropertyValue` entities for the values taken by these parameters during the run.  
        The `PropertyValue` are added to the main CreateAction under `object` which is the entry for values taken by input parameters.   
        """
        # Parse the parameters from the json
        # the jsons are not actually directly inputs of the BatchConvert workflow, since they are created automatically
        # rather input of the subworkflows (actual nexflow pipeline)

        # Loop over the entries of the param dict, checking if differing from default
        add_log = False
        for key, value in self._json_param.items():
            
            if key == "keep_workdir" and value : 
                add_log = True
            
            if key in self._json_default_param:
                
                default_value = self._json_default_param[key]
                
                if value != default_value:
                    self._add_input_and_value_entities_for_parameter(
                        input_key = key,
                        input_value = value
                        )
                #else value is default, nothing to do
            
            else : # if the key is not even in the default parameters then also add it
                self._add_input_and_value_entities_for_parameter(
                    input_key = key,
                    input_value = value
                    )
        
        if add_log:
            
            logfile_formal_parameter = self._add_FormalParameter(
                id = "#nextflow-log-file",
                name = "nextflow.log",
                additionalType = "File",
                description = "Nextflow log file. Only saved if parameter 'keep_workdir' is True."
            )
            
            self.main_wf.append_to("output", logfile_formal_parameter)

            if not "workdir" in self._json_param:
                warnings.warn("Could not find key 'workdir' in file params.json. Log file wont be part of the WorkflowRunCrate.")
            
            else:

                log_file = Path(self._json_param["workdir"], "logs", ".nextflow.log")

                # Check if log file is existing
                if log_file.is_file() : 
                    logfile_entity = self.crate.add_file(source = log_file,
                                                         dest_path = "nextflow.log", # saved it in the crate as nextflow.log otherwise hidden file when prefixed with .
                                                         properties = {"name" : "nextflow.log/value",
                                                                       "encodingFormat" : "text/plain",
                                                                       "exampleOfWork" : logfile_formal_parameter})
                    
                    # add the log file to the main action results, so it is listed as output of the run
                    self.main_action.append_to("result", logfile_entity) 
                    
                    # vice-versa, also mention the log File entity in the FormalParameter
                    logfile_formal_parameter["workExample"] = logfile_entity


                else:
                    warnings.warn(f"Could not find log file {log_file}, it won't be added to WorkflowRunCrate.")


    def _add_FormalParameter(self,
                           id: str, 
                           additionalType : Literal["Text", "Boolean", "Integer", "Dataset", "File"], 
                           name:str, 
                           description : Optional[str] = None,
                           valueRequired = False,
                           defaultValue = None) -> ContextEntity:
        """
        Create a FormalParameter to describe an input or output of a workflow.  
        The FormalParameter is created in the crate as a separate entity, and returned by the function.  
        The caller should then associate the returned FormalParameter entity to the workflow of interest. 
        """
        properties = {"@type": "FormalParameter",
                      "additionalType" : additionalType,
                      "valueRequired" : valueRequired,
                      "conformsTo": {
                                "@id": "https://bioschemas.org/profiles/FormalParameter/1.0-RELEASE"
                                },
                      "name" : name
                    }
        
        if description:
            properties["description"] = description

        if defaultValue:
            properties["defaultValue"] = defaultValue

        return cast(ContextEntity, self.crate.add(ContextEntity(self.crate, 
                                                                identifier = get_identifier(id),
                                                                properties = properties)))
    

    def _add_PropertyValue(self, value, param_entity : ContextEntity) -> ContextEntity:
        """
        Create a PropertyValue entity with the value taken by a param_entity during a run.  
        The PropertyValue will have the same id than the param entity with suffix "/value".   
        The field 'name' is however the same than the FormalParameter.  
        The returned PropertyValue can be listed nder 'object' or 'result' of the main CreateAction (the one for the main run).
        """
        properties = {"@type" : "PropertyValue",
                      "name"  : param_entity["name"],
                      "value" : value
                      }
                    
        propertyValueEntity = cast(ContextEntity, self.crate.add(ContextEntity(self.crate,
                                                                                identifier = f"{param_entity.id}/value",
                                                                                properties = properties)))
        propertyValueEntity["exampleOfWork"] = param_entity

        return propertyValueEntity
    

    def _add_input_and_value_entities_for_parameter(self, input_key : str, input_value:int | str | bool):
        """
        Create a FormalParameter and associated value entity for a pair of (input, value) 
        representing a workflow parameter (so other than a directory or file).  
        Add the FormalParameter entity to the list of inputs of the workflow, and the value entity to the main CreateAction under 'object'.
        """

        try:
            formal_parameter_type = self.PY_TYPE_TO_RO_TYPE[type(input_value)]
        except KeyError:
            raise TypeError("input_value should be of type int, str or bool.")

        
        ## First FormalParameter
        formal_param_entity = self._add_FormalParameter(
            id = input_key,
            additionalType = formal_parameter_type, # type: ignore
            name = input_key,
            description = self.PARAMETERS_TO_DESCRIPTION.get(input_key), # add custom description if available, None otherwise 
            valueRequired = input_key in ("in_path", "out_path"),
        )

        ## Then associated PropertyValue entity
        property_value_entity = self._add_PropertyValue(
            value=input_value, 
            param_entity=formal_param_entity
        )
        
        # Mention the PropertyValue entity in the FormalParameter, as an example of work
        formal_param_entity["workExample"] = property_value_entity

        # Add the FormalParameter to the input of the main workflow
        self.main_wf.append_to("input", formal_param_entity)

        # Add the PropertyValue entity to the main action, 
        # as an object (i.e input parameter value) for a run
        self.main_action.append_to("object", property_value_entity)


    def _parse_params_and_reorganize_files(self):
        """
        IMPORTANT : This function can also move the input and/or output directory of images to subdirectories to avoid data-duplication !  

        After a run of BatchConvert, add both the params.json and params.json.default to the crate (normally in home/.batchConvert/params).  
        Also parse those files to try find out which parameters values differ from the default, i.e were potentially passed to the batchconvert command line utils.  
        Typically, includes the input and output directory.  
        Some parameters will be listed in the rocrate json although they were not passed to the cmd line i.e they were taking the default value, the result is however the same than omitting them.   
        There is not much simpler way to recover these "custom" values, having always a consistent parameter naming.  
        
        And adds the input and output directory as Dataset in the crate.  
        """
        
        # Create a variable for the input/output directory 
        # used later on when saving the crate
        in_dir  = Path(self._json_param["in_path"]) 
        out_dir = Path(self._json_param["out_path"])

        # Handle the different cases of input/output directory structure
        # because the rpyrocrate package copy the directory referenced in the json, unless they are already in the right place
        # so to avoid duplication we move the data already in the right place

        # Case 1 : input and output are in the same directory
        # then move them to a subdirectory and use the newly created parent as the crate
        # "least astonishment principle" 
        if in_dir.parent == out_dir.parent:
            
            parent = in_dir.parent

            self.crate_dir = parent.joinpath(f"batchconvert_wfrun_rocrate_{time.strftime('%Y_%m_%d_%H%M')}")
            self.crate_dir.mkdir()

            # Move the input and output dir to the crate dir
            image_dir = self.crate_dir.joinpath(in_dir.name)
            shutil.move(in_dir, image_dir) # in dir is the original input directory, its content is then moved to crate/in_dir

            converted_image_dir = self.crate_dir.joinpath(out_dir.name)
            shutil.move(out_dir, converted_image_dir)

        # if the output dir is a subdirectory of the input directory
        # then move the images to a subdirectory of the original input dir 
        # and use the original input dir as the crate
        elif out_dir.is_relative_to(in_dir):
            
            self.crate_dir = in_dir 
            
            # Move the original images to a subdirectory of the input directory
            # Dont move the subdirectyory of the converted images though
            image_dir = move_content_to_subdir(base_directory = in_dir,
                                               subdirectory_name = "images",
                                               exclude = [out_dir])
            
            converted_image_dir = out_dir
        
        # any other case : the input directory is somewhere and the input dir somewhere unrelated, then move the content of the output directory to a subdirectory
        # and use the original output directory as the crate directory
        # TODO if the output directory contains stuff already this content also get moved to the newly created subdirectory, could be avoided?
        else :
            self.crate_dir = out_dir
            image_dir = in_dir
            
            converted_image_dir = move_content_to_subdir(base_directory = out_dir,
                                                         subdirectory_name = "converted_images")
        
        # Input directory
        # Add a FormalParameter of additionalType "Dataset" (RO vocabulary for directory)
        # this is in addition to the string 'in_path' passed to the command line
        # also add a directory entity with the value for the input directory used for the run
        # not sure if the FormalParameter with type "Dataset@ should be listed, not really a parameter of the workflow
        
        # First the FormalParameter, which is a description of the input directory, using the type Dataset
        # so different from the string "in_path"
        inputdir_formal_param = self._add_FormalParameter(
            id = "#directory_original_images",
            additionalType = "Dataset",
            name = "directory_original_images",
            description = "Directory with images in the original/proprietary file format (pff) to convert. "
             "This directory might be slightly different from the value passed to 'in_path' in the command line : "
             "when creating the ROCrate, directories are reorganised to avoid duplicating images.")

        self.main_wf.append_to("input", inputdir_formal_param)
        
        # Then the value entity, which is the actual directory used for the run
        inputdir_value_entity = self.crate.add_directory(source = image_dir,
                                                         properties = {"name": "directory_original_images/value",
                                                                        "description" : "Directory with original images, used as input for this run.",
                                                                        "exampleOfWork" : inputdir_formal_param} ) 
        inputdir_formal_param["workExample"] = inputdir_value_entity

        # also add this value entity to the main action, as input (so called object)
        self.main_action.append_to("object", inputdir_value_entity)

        
        # Output directory
        # Add a FormalParameter under 'output' of the workflow
        # and add a corresponding value entity for the directory
        # Not to confuse with the FormalParameter outdir of type string, 
        # which is an input parameter to say where to save the images, not the actual directory entity
        outputdir_formal_param = self._add_FormalParameter(id = "#directory_converted_images",
                                                        additionalType = "Dataset", # for directories
                                                        name = "directory_converted_images",
                                                        description = "Directory that will contain the converted images (ometiff or omezarr). It might be slightly different than the value passed in the command line for 'out_path' : when writing the ROCrate, directories might be reorganised to prevent duplicatng images."
                                                        )
        
        self.main_wf.append_to("output", outputdir_formal_param)

        outputdir_value_entity  = self.crate.add_directory(source = converted_image_dir,
                                                            properties = {"name": "directory_converted_images/value",
                                                                          "description" : "Directory with converted images for this run.",
                                                                          "exampleOfWork" : outputdir_formal_param
                                                                            }) 
        
        # Also reference the output_dir_entity (the value), from the FormalParameter (the parameter definition)
        # as well as in the main action results
        outputdir_formal_param["workExample"] = outputdir_value_entity
        self.main_action.append_to("result", outputdir_value_entity)

                    
    def save_crate(self):
        """
        Save the crate to the original output directory passed to the BatchConvert tool.  
        This function will also parse the params file with the parameter values used during the run and move the files around accordingly (to avoid data-duplication).   
        """
        self._parse_params_and_reorganize_files()
        
        conversion_format = self._json_param["output_type"]
        src_dir_name = os.path.basename(self._json_param["in_path"])

        # Add name, description and license to root dataset, needed for a valid crate
        if not self.crate.name :
            self.crate.name = f"Workflow Run RO-Crate - Conversion of images with BatchConvert"

        if not self.crate.description :
            self.crate.description = f"Workflow run RO Crate describing conversion of images in directory '{src_dir_name}' to format {conversion_format} using BatchConvert"
                
        self.crate.write(self.crate_dir)
    

def move_content_to_subdir(base_directory:str|Path, subdirectory_name = "converted_images", exclude:List[str]|List[Path] = []) -> Path:
    """
    Move all the content of a directory to a subdirectory, create it if not existing.  
    Return the path to the subdirectory.
    """
    if isinstance(base_directory, str):
        base_directory = Path(base_directory)
    
    subdir = base_directory.joinpath(subdirectory_name)

    # Create the directory otherwise create a weird executable file and the files are lost
    if not subdir.exists():
        subdir.mkdir(parents = True) # recursive i.e create parents if needed

    exclude = [Path(path) for path in exclude]

    for file in base_directory.iterdir():
        
        if file in exclude :
            continue

        shutil.move(file, subdir)
    
    return subdir

def write_workflow_run_crate(batch_convert_repo_dir:str, param_dir:Optional[str] = None) :
    """
    After converting a dataset with batch_convert, call this function to turn the dest_dir into a Workflow Run ROCrate.  
    This function will actually move the converted images to a subdirectory "images" in the dest_dir.  
    It also copies the files batchconvert, batchconvert.sh, pff2ometiff.nf, pff2omezarr.nf to the RO crate.    
    A ro-crate-metadata.json is written in dest_dir, which in effect makes the directory a RO_crate.  
    TODO add the rest of the files needed for execution
    
    batch_convert_repo_dir
    ---------------------
    path to the root directoy of batchconvert where the batchconvert utility and nextflow files are (e.g pff2ometiff.nf)  

    src_dir
    -------
    directory of the original images to convert
    """
    crate_maker = BatchConvert_RunCrateMaker(batch_convert_repo_dir, 
                                             param_dir = param_dir)
    
    crate_maker.save_crate()

if __name__ ==  "__main__" :
    crate_maker = BatchConvert_RunCrateMaker(batch_convert_root_directory="..")